










































227/227 [==============================] - 91s 384ms/step - loss: 9.0335











































227/227 [==============================] - 86s 381ms/step - loss: 8.9870










































227/227 [==============================] - 87s 382ms/step - loss: 8.9371











































227/227 [==============================] - 88s 386ms/step - loss: 8.8820











































227/227 [==============================] - 87s 384ms/step - loss: 8.8184











































227/227 [==============================] - 88s 387ms/step - loss: 8.7427










































227/227 [==============================] - 87s 382ms/step - loss: 8.6511











































227/227 [==============================] - 88s 386ms/step - loss: 8.5405











































227/227 [==============================] - 87s 384ms/step - loss: 8.4071










































227/227 [==============================] - 88s 386ms/step - loss: 8.2530











































227/227 [==============================] - 88s 386ms/step - loss: 8.0936












































227/227 [==============================] - 88s 389ms/step - loss: 7.9603










































227/227 [==============================] - 87s 383ms/step - loss: 7.8580











































227/227 [==============================] - 87s 384ms/step - loss: 7.7644











































227/227 [==============================] - 88s 387ms/step - loss: 7.6699











































227/227 [==============================] - 87s 384ms/step - loss: 7.5774










































227/227 [==============================] - 87s 385ms/step - loss: 7.4927











































227/227 [==============================] - 88s 387ms/step - loss: 7.4181












































227/227 [==============================] - 88s 387ms/step - loss: 7.3508










































227/227 [==============================] - 87s 385ms/step - loss: 7.2876











































227/227 [==============================] - 87s 384ms/step - loss: 7.2268











































227/227 [==============================] - 88s 386ms/step - loss: 7.1686













































227/227 [==============================] - 92s 405ms/step - loss: 7.1141











































227/227 [==============================] - 92s 403ms/step - loss: 7.0628











































227/227 [==============================] - 88s 387ms/step - loss: 7.0151











































227/227 [==============================] - 88s 387ms/step - loss: 6.9708











































227/227 [==============================] - 88s 386ms/step - loss: 6.9297











































227/227 [==============================] - 88s 386ms/step - loss: 6.8909











































227/227 [==============================] - 88s 388ms/step - loss: 6.8544











































227/227 [==============================] - 87s 383ms/step - loss: 6.8192
/home/robert/miniconda3/envs/gpu/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.
  saving_api.save_model(
/home/robert/miniconda3/envs/gpu/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 2-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/home/robert/miniconda3/envs/gpu/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 3-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)
/home/robert/miniconda3/envs/gpu/lib/python3.11/site-packages/nltk/translate/bleu_score.py:552: UserWarning:
The hypothesis contains 0 counts of 4-gram overlaps.
Therefore the BLEU score evaluates to 0, independently of
how many N-gram overlaps of lower order it contains.
Consider using lower n-gram order or use SmoothingFunction()
  warnings.warn(_msg)